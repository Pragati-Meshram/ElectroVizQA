## ElectroVizQA 

**ElectroVizQA: A Benchmark for Electronics Visual Question Answering**

[![Paper](https://img.shields.io/badge/arXiv-2412.00102-b31b1b.svg)](https://arxiv.org/abs/2412.00102)

---

## Citation
If you find our work useful, please consider citing:
```
    @misc{meshram2024electrovizqamultimodalllmsperform,
      title={ElectroVizQA: How well do Multi-modal LLMs perform in Electronics Visual Question Answering?}, 
      author={Pragati Shuddhodhan Meshram and Swetha Karthikeyan and Bhavya and Suma Bhat},
      year={2024},
      eprint={2412.00102},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2412.00102}, 
}
```
---

## üìò Overview

**ElectroVizQA** is a benchmark dataset designed to evaluate **multimodal large language models (MLLMs)** in the domain of **digital electronics visual question answering**. It consists of curated circuit diagrams, associated questions, and structured answers designed to challenge both visual understanding and domain-specific reasoning.

This dataset supports research in:
- Multimodal reasoning
- Engineering diagram understanding
- Domain-specific VQA

---

## üóÇÔ∏è Dataset Structure

The dataset includes:
- **Circuit diagrams** (PNG/JPG/PDF formats)
- **VQA pairs**: Each image is accompanied by multiple questions and answers.
